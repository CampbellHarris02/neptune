{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c438359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import laplace\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Histogram setup\n",
    "bin_width = 0.1\n",
    "bin_range = 8\n",
    "bins = np.arange(-bin_range * bin_width, (bin_range + 1) * bin_width, bin_width)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "n_bins = len(bin_centers)\n",
    "\n",
    "# Histograms (decayed over time)\n",
    "hist_open = np.zeros(n_bins)\n",
    "hist_high = np.zeros(n_bins)\n",
    "hist_low = np.zeros(n_bins)\n",
    "hist_close = np.zeros(n_bins)\n",
    "\n",
    "# Parameters\n",
    "decay_rate = 0.9  # exponential decay factor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configurable parameters\n",
    "n_centroids = 8  # Number of quantization centroids\n",
    "\n",
    "bin_width = 0.1\n",
    "\n",
    "bins = np.arange(-bin_range * bin_width, (bin_range + 1) * bin_width, bin_width)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "n_bins = len(bin_centers)\n",
    "\n",
    "# Histograms\n",
    "\n",
    "histogram_vectors = []\n",
    "\n",
    "\n",
    "BOUNDARY = 0.08 #   +/- 8%\n",
    "\n",
    "\n",
    "# Laplace + Quantizer helpers\n",
    "def fit_asymmetric_laplace_from_histogram(bin_centers, counts, loc=0):\n",
    "    counts = np.asarray(counts)\n",
    "    x = bin_centers - loc\n",
    "    left = x < 0\n",
    "    right = x >= 0\n",
    "    weights_left = counts[left]\n",
    "    weights_right = counts[right]\n",
    "    x_left = np.abs(x[left])\n",
    "    x_right = np.abs(x[right])\n",
    "    b_left = np.sum(weights_left * x_left) / np.sum(weights_left) if np.sum(weights_left) > 0 else 0.05\n",
    "    b_right = np.sum(weights_right * x_right) / np.sum(weights_right) if np.sum(weights_right) > 0 else 0.05\n",
    "    return b_left, b_right\n",
    "\n",
    "def lloyd_max_quantizer(x, pdf, n_centroids, max_iter=5000, tol=1e-5):\n",
    "    pmf = pdf / np.sum(pdf)\n",
    "    centroids = np.linspace(x.min(), x.max(), n_centroids)\n",
    "    for _ in range(max_iter):\n",
    "        boundaries = np.convolve(centroids, [0.5, 0.5], mode='valid')\n",
    "        partitions = np.digitize(x, boundaries)\n",
    "        new_centroids = []\n",
    "        for k in range(n_centroids):\n",
    "            mask = partitions == k\n",
    "            if np.any(mask):\n",
    "                weights = pmf[mask]\n",
    "                new_centroids.append(np.sum(x[mask] * weights) / np.sum(weights))\n",
    "            else:\n",
    "                new_centroids.append(centroids[k])\n",
    "        new_centroids = np.array(new_centroids)\n",
    "        if np.allclose(new_centroids, centroids, atol=tol):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return centroids\n",
    "\n",
    "\n",
    "\n",
    "def get_centroids(df):\n",
    "    hist_combined = np.zeros(n_bins)  # ✅ now local to function\n",
    "    centroid_array = []  # also make this local to avoid appending across multiple runs\n",
    "\n",
    "    for frame in range(len(df)):\n",
    "        row = df.iloc[frame]\n",
    "        base_price = row[\"open\"]\n",
    "        prices = np.array([row[\"open\"], row[\"high\"], row[\"low\"], row[\"close\"]])\n",
    "        deltas = prices - base_price\n",
    "\n",
    "        hist_combined *= decay_rate\n",
    "        hist_combined += np.histogram(deltas, bins=bins)[0]\n",
    "\n",
    "        hist = hist_combined.copy()\n",
    "        b_left, b_right = fit_asymmetric_laplace_from_histogram(bin_centers, hist, loc=0)\n",
    "\n",
    "        x = np.linspace(bin_centers[0], bin_centers[-1], 300)\n",
    "        y = np.where(x < 0,\n",
    "                     0.5 * np.exp(x / b_left) / b_left,\n",
    "                     0.5 * np.exp(-x / b_right) / b_right)\n",
    "        y *= np.sum(hist) * bin_width  # Normalize to histogram mass\n",
    "\n",
    "        centroids = lloyd_max_quantizer(x, y, n_centroids)\n",
    "        centroid_array.append(centroids)\n",
    "\n",
    "    return centroid_array\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cluster_centroids(centroid_series, n_clusters=8, random_state=42):\n",
    "    \"\"\"\n",
    "    Cluster per-frame centroid vectors using KMeans and return cluster labels,\n",
    "    the fitted model, and a nearest-neighbor quantizer function.\n",
    "    \"\"\"\n",
    "    # Convert to 2D matrix: (n_frames, n_centroids)\n",
    "    centroid_matrix = np.stack(centroid_series.to_numpy())\n",
    "\n",
    "    # Fit KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(centroid_matrix)\n",
    "\n",
    "    # Define nearest-neighbor quantizer\n",
    "    def quantize_centroids(new_centroids):\n",
    "        new_centroids = np.atleast_2d(new_centroids)\n",
    "        return kmeans.predict(new_centroids)\n",
    "\n",
    "    return labels, kmeans, quantize_centroids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_good_clusters(df):\n",
    "    # Precompute midprice for each row\n",
    "    df[\"mid_price\"] = df[[\"open\", \"high\", \"low\", \"close\"]].median(axis=1)\n",
    "\n",
    "    # Store results\n",
    "    cluster_success_counts = {}\n",
    "    cluster_total_counts = {}\n",
    "\n",
    "    # Loop over each row (time step)\n",
    "    for i in range(len(df)):\n",
    "        cluster = df.iloc[i][\"laplace_cluster\"]\n",
    "        midpoint = df.iloc[i][\"mid_price\"]\n",
    "\n",
    "        upper = (1 + BOUNDARY) * midpoint\n",
    "        lower = (1 - BOUNDARY) * midpoint\n",
    "\n",
    "        # Look ahead in time\n",
    "        future_prices = df.iloc[i+1:][\"mid_price\"].values\n",
    "\n",
    "        hit_upper = np.argmax(future_prices >= upper) if np.any(future_prices >= upper) else None\n",
    "        hit_lower = np.argmax(future_prices <= lower) if np.any(future_prices <= lower) else None\n",
    "\n",
    "        success = False\n",
    "        if hit_upper is not None and hit_lower is not None:\n",
    "            success = hit_upper < hit_lower  # rises before it falls\n",
    "        elif hit_upper is not None:\n",
    "            success = True  # only rises\n",
    "        else:\n",
    "            success = False  # never rises\n",
    "\n",
    "        # Tally\n",
    "        cluster_total_counts[cluster] = cluster_total_counts.get(cluster, 0) + 1\n",
    "        if success:\n",
    "            cluster_success_counts[cluster] = cluster_success_counts.get(cluster, 0) + 1\n",
    "\n",
    "    # Compute success ratios\n",
    "    success_ratios = {}\n",
    "    for cluster in cluster_total_counts:\n",
    "        total = cluster_total_counts[cluster]\n",
    "        success = cluster_success_counts.get(cluster, 0)\n",
    "        ratio = success / (total + 2) # +2 Wilson interval\n",
    "        success_ratios[cluster] = ratio\n",
    "\n",
    "    # Display as DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"cluster\": list(success_ratios.keys()),\n",
    "        \"success_ratio\": list(success_ratios.values()),\n",
    "        \"successes\": [cluster_success_counts.get(c, 0) for c in success_ratios],\n",
    "        \"total\": [cluster_total_counts[c] for c in success_ratios]\n",
    "    }).sort_values(\"success_ratio\", ascending=False)\n",
    "\n",
    "    print(summary_df)\n",
    "    \n",
    "    return df, summary_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_kraken_ohlcv(symbol=\"BTC/USD\", timeframe=\"1h\", lookback_days=30, limit_per_fetch=720, pause=1.2):\n",
    "    \"\"\"\n",
    "    Fetch OHLCV price data from Kraken for a given symbol and lookback period.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Kraken trading pair (e.g., \"BTC/USD\", \"ETH/USD\")\n",
    "        timeframe (str): OHLCV timeframe (e.g., '1h', '1d')\n",
    "        lookback_days (int): How many days of data to fetch\n",
    "        limit_per_fetch (int): Max candles per API call\n",
    "        pause (float): Delay between calls to avoid rate limits\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: OHLCV dataframe with timestamp index\n",
    "    \"\"\"\n",
    "    kraken = ccxt.kraken({\n",
    "        'apiKey': os.getenv(\"KRAKEN_API_KEY\"),\n",
    "        'secret': os.getenv(\"KRAKEN_API_SECRET\"),\n",
    "        'enableRateLimit': True,\n",
    "    })\n",
    "\n",
    "    end_time = datetime.now(timezone.utc)\n",
    "    start_time = end_time - timedelta(days=lookback_days)\n",
    "    since = int(start_time.timestamp() * 1000)\n",
    "\n",
    "    all_ohlcv = []\n",
    "\n",
    "    print(f\"⏳ Fetching last {lookback_days} days of {symbol} ({timeframe}) data...\")\n",
    "\n",
    "    try:\n",
    "        ohlcv = kraken.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=limit_per_fetch)\n",
    "        all_ohlcv.extend(ohlcv)\n",
    "        #print(f\"✅ Got {len(ohlcv)} candles — latest: {pd.to_datetime(ohlcv[-1][0], unit='ms')}\")\n",
    "        since = ohlcv[-1][0] + 1\n",
    "\n",
    "        #time.sleep(pause)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}. Retrying...\")\n",
    "        #time.sleep(5)\n",
    "\n",
    "    df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    print(f\"✅ Fetched {len(df)} rows for {symbol}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5699c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Fetching and processing BTC/USD from Kraken...\n",
      "⏳ Fetching last 30 days of BTC/USD (1h) data...\n",
      "✅ Fetched 720 rows for BTC/USD\n",
      "   cluster  success_ratio  successes  total\n",
      "5        6       0.942857         33     33\n",
      "6        3       0.913793         53     56\n",
      "1        0       0.684971        237    344\n",
      "3        4       0.600000         30     48\n",
      "4        7       0.279570         26     91\n",
      "2        2       0.038462          2     50\n",
      "0        1       0.000000          0     90\n",
      "7        5       0.000000          0      8\n",
      "\n",
      "🚀 Fetching and processing ETH/USD from Kraken...\n",
      "⏳ Fetching last 30 days of ETH/USD (1h) data...\n",
      "✅ Fetched 720 rows for ETH/USD\n",
      "   cluster  success_ratio  successes  total\n",
      "6        4       0.909091         20     20\n",
      "5        5       0.575000         23     38\n",
      "4        1       0.563830        106    186\n",
      "7        0       0.533333         16     28\n",
      "3        7       0.513761         56    107\n",
      "2        2       0.394191         95    239\n",
      "1        6       0.376812         26     67\n",
      "0        3       0.000000          0     35\n",
      "\n",
      "🚀 Fetching and processing SOL/USD from Kraken...\n",
      "⏳ Fetching last 30 days of SOL/USD (1h) data...\n",
      "✅ Fetched 720 rows for SOL/USD\n",
      "   cluster  success_ratio  successes  total\n",
      "1        2       0.655172         38     56\n",
      "5        0       0.653846        102    154\n",
      "6        7       0.642458        115    177\n",
      "2        1       0.390476         41    103\n",
      "4        5       0.383333         46    118\n",
      "3        6       0.341463         28     80\n",
      "7        3       0.090909          3     31\n",
      "0        4       0.000000          0      1\n",
      "✅ Saved ranked coin scores to ranked_coins.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assets = {\n",
    "        \"BTC/USD\": \"data/centroids/btc_usd_cluster_centers.json\",\n",
    "        \"ETH/USD\": \"data/centroids/eth_usd_cluster_centers.json\",\n",
    "        \"SOL/USD\": \"data/centroids/sol_usd_cluster_centers.json\",\n",
    "    }\n",
    "\n",
    "    load_dotenv()\n",
    "    cluster_models = {}\n",
    "    coin_details = {}  # ⬅️ store full record per coin\n",
    "\n",
    "    for symbol, json_file in assets.items():\n",
    "        print(f\"\\n🚀 Fetching and processing {symbol} from Kraken...\")\n",
    "\n",
    "        df = fetch_kraken_ohlcv(symbol)\n",
    "        df = df[['open', 'high', 'low', 'close']].dropna()\n",
    "\n",
    "        centroids = get_centroids(df)\n",
    "        df[\"laplace_centroids\"] = centroids\n",
    "\n",
    "        labels, kmeans_model, quantize_centroids = cluster_centroids(df[\"laplace_centroids\"], n_clusters=8)\n",
    "        df[\"laplace_cluster\"] = labels\n",
    "\n",
    "        cluster_models[symbol] = {\n",
    "            \"model\": kmeans_model,\n",
    "            \"quantizer\": quantize_centroids\n",
    "        }\n",
    "\n",
    "        df_clusters, df_summary = find_good_clusters(df)\n",
    "\n",
    "        current_bin = int(df_clusters[\"laplace_cluster\"].iloc[-1])\n",
    "        current_price = float(df_clusters[\"mid_price\"].iloc[-1])\n",
    "        coin_score = float(df_summary.loc[df_summary[\"cluster\"] == current_bin, \"success_ratio\"].values[0])\n",
    "\n",
    "        coin_details[symbol] = {\n",
    "            \"score\": round(coin_score, 4),\n",
    "            \"price\": round(current_price, 8),\n",
    "            \"sell_price\": round(current_price * (1 - BOUNDARY), 8),\n",
    "            \"drop_order_price\": round(current_price * (1 + BOUNDARY), 8)\n",
    "        }\n",
    "\n",
    "    # 🔃 Sort by score descending\n",
    "    sorted_items = sorted(coin_details.items(), key=lambda x: -x[1][\"score\"])\n",
    "    sorted_dict = {symbol: details for symbol, details in sorted_items}\n",
    "\n",
    "    # 💾 Save to JSON\n",
    "    with open(\"ranked_coins.json\", \"w\") as f:\n",
    "        json.dump(sorted_dict, f, indent=2)\n",
    "\n",
    "    print(\"✅ Saved ranked coin scores to ranked_coins.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d62898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'laplace_centroids', 'laplace_cluster',\n",
       "       'mid_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e22615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_coin_bin = int(df[\"laplace_cluster\"].iloc[-1])\n",
    "current_coin_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9513a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>successes</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>102</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>115</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.390476</td>\n",
       "      <td>41</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>46</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  success_ratio  successes  total\n",
       "1        2       0.655172         38     56\n",
       "5        0       0.653846        102    154\n",
       "6        7       0.642458        115    177\n",
       "2        1       0.390476         41    103\n",
       "4        5       0.383333         46    118\n",
       "3        6       0.341463         28     80\n",
       "7        3       0.090909          3     31\n",
       "0        4       0.000000          0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fbd70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6551724137931034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_score = float(df_summary.loc[df_summary[\"cluster\"] == current_coin_bin, \"success_ratio\"].values[0])\n",
    "coin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd9f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
